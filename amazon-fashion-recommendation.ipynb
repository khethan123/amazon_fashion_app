{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:13.768370Z","iopub.execute_input":"2023-05-25T09:25:13.768753Z","iopub.status.idle":"2023-05-25T09:25:13.805308Z","shell.execute_reply.started":"2023-05-25T09:25:13.768724Z","shell.execute_reply":"2023-05-25T09:25:13.803911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:18.344852Z","iopub.execute_input":"2023-05-25T09:25:18.345249Z","iopub.status.idle":"2023-05-25T09:25:18.351696Z","shell.execute_reply.started":"2023-05-25T09:25:18.345221Z","shell.execute_reply":"2023-05-25T09:25:18.349774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fashion = pd.read_json('/kaggle/input/amazon-apparel-dataset/tops_fashion.json')\nprint('Number of Data Points: ', fashion.shape[0])\nprint('Number of Features   : ', fashion.shape[1])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:23.873397Z","iopub.execute_input":"2023-05-25T09:25:23.873761Z","iopub.status.idle":"2023-05-25T09:25:29.573857Z","shell.execute_reply.started":"2023-05-25T09:25:23.873734Z","shell.execute_reply":"2023-05-25T09:25:29.572180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> we had a json file which has shape (183138, 19) and now below we will check which and all data to keep and which and all to be ingnored depending on the importance ","metadata":{}},{"cell_type":"code","source":"fashion.columns","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:33.123607Z","iopub.execute_input":"2023-05-25T09:25:33.123988Z","iopub.status.idle":"2023-05-25T09:25:33.130967Z","shell.execute_reply.started":"2023-05-25T09:25:33.123961Z","shell.execute_reply":"2023-05-25T09:25:33.130134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**since this is a project to basically build an end to end clothing recommendation system lets use the following features:**\n\n* asin -> Amazon Standard Identification Number\n* product_type_name -> Type of the apperal, ex: SHIRT/TSHIRT\n* formatted_price -> Price of the product\n* color -> Color information of apparel, it can contain many colors as a value ex: red and black stripes\n* brand -> Brand to which the product belongs to\n* title -> Title of the product\n* medium_image_url -> url of the image\n\nwe can use other data as well but since it won't matter much","metadata":{}},{"cell_type":"code","source":"fashion_data = fashion[['asin', 'brand', 'color', 'medium_image_url', 'product_type_name', 'title', 'formatted_price']]","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:36.377408Z","iopub.execute_input":"2023-05-25T09:25:36.377772Z","iopub.status.idle":"2023-05-25T09:25:36.414566Z","shell.execute_reply.started":"2023-05-25T09:25:36.377744Z","shell.execute_reply":"2023-05-25T09:25:36.412538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of Data Points: ', fashion_data.shape[0])\nprint('Number of Features   : ', fashion_data.shape[1])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:40.648537Z","iopub.execute_input":"2023-05-25T09:25:40.649223Z","iopub.status.idle":"2023-05-25T09:25:40.655608Z","shell.execute_reply.started":"2023-05-25T09:25:40.649170Z","shell.execute_reply":"2023-05-25T09:25:40.654645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fashion_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:43.951177Z","iopub.execute_input":"2023-05-25T09:25:43.952560Z","iopub.status.idle":"2023-05-25T09:25:43.975816Z","shell.execute_reply.started":"2023-05-25T09:25:43.952503Z","shell.execute_reply":"2023-05-25T09:25:43.973954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Now let's look at the products that we have**","metadata":{}},{"cell_type":"code","source":"fashion_data['product_type_name'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:47.231511Z","iopub.execute_input":"2023-05-25T09:25:47.231898Z","iopub.status.idle":"2023-05-25T09:25:47.314406Z","shell.execute_reply.started":"2023-05-25T09:25:47.231867Z","shell.execute_reply":"2023-05-25T09:25:47.313368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# so let's see all the unique fashion that we have\nfashion_data['product_type_name'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:50.279111Z","iopub.execute_input":"2023-05-25T09:25:50.279503Z","iopub.status.idle":"2023-05-25T09:25:50.331901Z","shell.execute_reply.started":"2023-05-25T09:25:50.279477Z","shell.execute_reply":"2023-05-25T09:25:50.330454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's look at the 10 most frequent products\nfrom collections import Counter\n\ncount_product_type = Counter(list(fashion_data['product_type_name']))\ncount_product_type.most_common(10)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:53.612583Z","iopub.execute_input":"2023-05-25T09:25:53.613842Z","iopub.status.idle":"2023-05-25T09:25:53.692717Z","shell.execute_reply.started":"2023-05-25T09:25:53.613781Z","shell.execute_reply":"2023-05-25T09:25:53.691289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Nice, now let's look at the brands**","metadata":{}},{"cell_type":"code","source":"fashion_data['brand'].nunique()\nfashion_data['brand'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:25:57.255572Z","iopub.execute_input":"2023-05-25T09:25:57.256970Z","iopub.status.idle":"2023-05-25T09:25:57.404464Z","shell.execute_reply.started":"2023-05-25T09:25:57.256920Z","shell.execute_reply":"2023-05-25T09:25:57.403105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ok we have some missing values in brands. let's see the most frequent brand names\n\ncount_product_type = Counter(list(fashion_data['brand']))\ncount_product_type.most_common(10)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:01.879450Z","iopub.execute_input":"2023-05-25T09:26:01.879829Z","iopub.status.idle":"2023-05-25T09:26:01.982747Z","shell.execute_reply.started":"2023-05-25T09:26:01.879802Z","shell.execute_reply":"2023-05-25T09:26:01.981719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Colors**","metadata":{}},{"cell_type":"code","source":"fashion_data['color'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:04.481482Z","iopub.execute_input":"2023-05-25T09:26:04.482109Z","iopub.status.idle":"2023-05-25T09:26:04.523684Z","shell.execute_reply.started":"2023-05-25T09:26:04.482077Z","shell.execute_reply":"2023-05-25T09:26:04.522312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#183138 - 64956 = 118182 missing values, approx. 64.5% missing colors\n#find the 10 most frequent colors\n#118182 values are None (missing)\n\ncount_colors = Counter(list(fashion_data['color']))\ncount_colors.most_common(10)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:06.871009Z","iopub.execute_input":"2023-05-25T09:26:06.871398Z","iopub.status.idle":"2023-05-25T09:26:06.927218Z","shell.execute_reply.started":"2023-05-25T09:26:06.871367Z","shell.execute_reply":"2023-05-25T09:26:06.925796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **What about price?**","metadata":{}},{"cell_type":"code","source":"fashion_data['formatted_price'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:09.582855Z","iopub.execute_input":"2023-05-25T09:26:09.583272Z","iopub.status.idle":"2023-05-25T09:26:09.612530Z","shell.execute_reply.started":"2023-05-25T09:26:09.583243Z","shell.execute_reply":"2023-05-25T09:26:09.611313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#183138 - 28395 = 154743 missing values, approx. 84.50% missing priceðŸ˜±\n\n\ncount_prices = Counter(list(fashion_data['formatted_price']))\ncount_prices.most_common(10)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:14.286772Z","iopub.execute_input":"2023-05-25T09:26:14.287152Z","iopub.status.idle":"2023-05-25T09:26:14.335081Z","shell.execute_reply.started":"2023-05-25T09:26:14.287122Z","shell.execute_reply":"2023-05-25T09:26:14.333848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Title**","metadata":{}},{"cell_type":"code","source":"fashion_data['title'].describe()\n\n#all of the products have a title & they are fairly descriptive of what the product is\n#we use titles extensively as they are short and informative","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:17.324667Z","iopub.execute_input":"2023-05-25T09:26:17.324994Z","iopub.status.idle":"2023-05-25T09:26:17.510848Z","shell.execute_reply.started":"2023-05-25T09:26:17.324970Z","shell.execute_reply":"2023-05-25T09:26:17.509684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's perform data cleaning/preprocessing. Here price has the highest null values so let's drop all the rows having null values","metadata":{}},{"cell_type":"code","source":"fashion_data = fashion_data.loc[~fashion_data['formatted_price'].isnull()]\nprint(\"Number of data points after eliminating null price values: \",fashion_data.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:20.382745Z","iopub.execute_input":"2023-05-25T09:26:20.383086Z","iopub.status.idle":"2023-05-25T09:26:20.404749Z","shell.execute_reply.started":"2023-05-25T09:26:20.383062Z","shell.execute_reply":"2023-05-25T09:26:20.403725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fashion_data = fashion_data.loc[~fashion_data['color'].isnull()]\nprint(\"Number of data points after eliminating null color values: \",fashion_data.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:23.826560Z","iopub.execute_input":"2023-05-25T09:26:23.826887Z","iopub.status.idle":"2023-05-25T09:26:23.849353Z","shell.execute_reply.started":"2023-05-25T09:26:23.826860Z","shell.execute_reply":"2023-05-25T09:26:23.847627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> so basically from 100% of the data available after removing null values we got \n15.499% of data which is still sufficient but it would have been better if we had full data without null values","metadata":{}},{"cell_type":"markdown","source":"**Now lets save this data using pickle and also download the images for products from the URLs provided**","metadata":{}},{"cell_type":"code","source":"import pickle\nfashion_data.to_pickle(\"/kaggle/working/28k_dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:34.814298Z","iopub.execute_input":"2023-05-25T09:26:34.814831Z","iopub.status.idle":"2023-05-25T09:26:34.911570Z","shell.execute_reply.started":"2023-05-25T09:26:34.814787Z","shell.execute_reply":"2023-05-25T09:26:34.909731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fashion_data = pd.read_pickle(\"/kaggle/working/28k_dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:37.556806Z","iopub.execute_input":"2023-05-25T09:26:37.557178Z","iopub.status.idle":"2023-05-25T09:26:37.590185Z","shell.execute_reply.started":"2023-05-25T09:26:37.557139Z","shell.execute_reply":"2023-05-25T09:26:37.588260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fashion_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:40.324825Z","iopub.execute_input":"2023-05-25T09:26:40.325156Z","iopub.status.idle":"2023-05-25T09:26:40.337380Z","shell.execute_reply.started":"2023-05-25T09:26:40.325132Z","shell.execute_reply":"2023-05-25T09:26:40.335873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's find the number of products having same titles since it isn't visible above\nsum(fashion_data.duplicated('title'))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:43.238060Z","iopub.execute_input":"2023-05-25T09:26:43.238444Z","iopub.status.idle":"2023-05-25T09:26:43.253499Z","shell.execute_reply.started":"2023-05-25T09:26:43.238417Z","shell.execute_reply":"2023-05-25T09:26:43.251913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"tooo many so let's start removing the duplicate titles\nfirst approach would be to remove titles having less than 5 words.","metadata":{}},{"cell_type":"code","source":"sorted_fashion_data = fashion_data[fashion_data['title'].apply(lambda x: len(x.split())>4)]\nprint(\"After removal of products with short description: \",sorted_fashion_data.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:46.341247Z","iopub.execute_input":"2023-05-25T09:26:46.341642Z","iopub.status.idle":"2023-05-25T09:26:46.378932Z","shell.execute_reply.started":"2023-05-25T09:26:46.341614Z","shell.execute_reply":"2023-05-25T09:26:46.377662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now sort the whole data based on title in alphabetical order\nsorted_fashion_data.sort_values('title', inplace=True, ascending=False)\nsorted_fashion_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:49.740767Z","iopub.execute_input":"2023-05-25T09:26:49.741145Z","iopub.status.idle":"2023-05-25T09:26:49.795863Z","shell.execute_reply.started":"2023-05-25T09:26:49.741115Z","shell.execute_reply":"2023-05-25T09:26:49.794845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\nindices = []\nfor i, row in sorted_fashion_data.iterrows():\n    indices.append(i)\n\nduplicate_ID = []\ni = 0\nj = 0\n\nnum_data_points = sorted_fashion_data.shape[0]\n\nwhile (i < num_data_points) and (j < num_data_points):\n    previous_i = i\n    a = sorted_fashion_data['title'].loc[indices[i]].split()\n    j = i+1\n    while (j < num_data_points):\n        b = sorted_fashion_data['title'].loc[indices[j]].split()\n        length = max(len(a), len(b))\n        count = sum(k[0] == k[1] for k in itertools.zip_longest(a, b))\n        if (length - count) > 2:\n            duplicate_ID.append(sorted_fashion_data['asin'].loc[indices[i]])\n            i = j\n            break\n        else:\n            j += 1\n    if previous_i == i:\n        break\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:26:52.623692Z","iopub.execute_input":"2023-05-25T09:26:52.624078Z","iopub.status.idle":"2023-05-25T09:26:54.711456Z","shell.execute_reply.started":"2023-05-25T09:26:52.624047Z","shell.execute_reply":"2023-05-25T09:26:54.710132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above code is trying to find similar products based on their titles. Here's a simplified explanation of what the code does:\n\n1. It creates an empty list called `indices` to store the row indices of the fashion data.\n2. It loops through the rows of the fashion data and appends the indices to the `indices` list.\n3. It initializes an empty list called `duplicate_ID` to store the duplicate product IDs.\n4. It sets up variables `i` and `j` to keep track of indices.\n5. It determines the total number of data points in the fashion data.\n6. It enters a while loop that continues as long as `i` and `j` are within the data points range.\n7. Inside the loop, it splits the title of the current row into a list of words, stored in variable `a`.\n8. It enters another while loop to sequentially search for similar products.\n9. Inside the second loop, it splits the title of the next row into a list of words, stored in variable `b`.\n10. It calculates the maximum length between the two lists of words.\n11. It iterates over the corresponding words in `a` and `b`, counting the number of matching words.\n12. If the difference between the maximum length and the count of matching words is greater than 2, it considers the products different.\n13. It appends the product ID of the first item (`indices[i]`) to the `duplicate_ID` list.\n14. It updates the value of `i` to the index of the second item (`indices[j]`).\n15. If the difference is not greater than 2, it increments `j` to check the next item.\n16. If the value of `previous_i` is equal to `i`, it means no new similar apparels were found, and the outer loop is exited.\n17. Finally, the code generates a list (`duplicate_ID`) containing the product IDs of the similar apparel products based on title comparison.\n\nIn summary, the code compares the titles of products and identifies duplicate or similar items by counting the number of words that differ. It collects the product IDs of the similar products into a list for further analysis or processing.","metadata":{}},{"cell_type":"code","source":"# now we removed the duplicates which differ only at the end\n\nfashion_data = sorted_fashion_data.loc[sorted_fashion_data['asin'].isin(duplicate_ID)]","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:27:02.142965Z","iopub.execute_input":"2023-05-25T09:27:02.143614Z","iopub.status.idle":"2023-05-25T09:27:02.164157Z","shell.execute_reply.started":"2023-05-25T09:27:02.143574Z","shell.execute_reply":"2023-05-25T09:27:02.162477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of data points after removing duplicates which differ only at the end: \",fashion_data.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:27:04.397453Z","iopub.execute_input":"2023-05-25T09:27:04.397811Z","iopub.status.idle":"2023-05-25T09:27:04.404128Z","shell.execute_reply.started":"2023-05-25T09:27:04.397781Z","shell.execute_reply":"2023-05-25T09:27:04.402729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We don't know how many images are actually present in the website at present, so let's only use those rows which have working urls**","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport requests\nfrom io import BytesIO\n\nfor index, row in fashion_data.iterrows():\n    try:\n        url = row['medium_image_url']\n        response = requests.get(url)\n        img = Image.open(BytesIO(response.content))\n\n    except Exception as e:\n        print(f\"Error processing image for row {index}: {e}\")\n        fashion_data.drop(index, inplace=True)\n\nprint(\"Number of data points after removing rows having error in retrieving images: \",fashion_data.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:27:07.654491Z","iopub.execute_input":"2023-05-25T09:27:07.654817Z","iopub.status.idle":"2023-05-25T10:02:06.575811Z","shell.execute_reply.started":"2023-05-25T09:27:07.654794Z","shell.execute_reply":"2023-05-25T10:02:06.574430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"17592-17509 = 83 is the amount of images that are not there anymore. **GOOD**\n\nIn the previous cell, we sorted whole data in alphabetical order of titles. Then, we removed titles which are adjacent and very similar title.\n\nBut there are some products whose titles are not adjacent but very similar.\n\nExamples:\nTitles-1\n UltraClub Women's Classic Wrinkle-Free Long Sleeve Oxford Shirt, Pink, XX-Large\n UltraClub Ladies Classic Wrinkle-Free Long-Sleeve Oxford Light Blue XXL\n\nTitles-2\n EVALY Women's Cool University Of UTAH 3/4 Sleeve Raglan Tee\n EVALY Women's Unique University Of UTAH 3/4 Sleeve Raglan Tees\n EVALY Women's New University Of UTAH 3/4-Sleeve Raglan Tshirt\n \nlet's try to remove these types of titles as well","metadata":{}},{"cell_type":"code","source":"#this code snippet takes significant amount of time\n#O(n^2) time. It takes about an hour to run on a decent system\n\nindices = list(fashion_data.index)\nduplicate_ID = []\n\nwhile len(indices) != 0:\n    i = indices.pop()\n    duplicate_ID.append(fashion_data['asin'].loc[i])\n\n    a = fashion_data['title'].loc[i].split()\n    \n    for j in indices:\n        b = fashion_data['title'].loc[j].split()\n        length = max(len(a), len(b))\n        count = sum(k[0] == k[1] for k in itertools.zip_longest(a, b))\n        \n        if (length - count) < 3:\n            indices.remove(j)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:08:39.056663Z","iopub.execute_input":"2023-05-25T10:08:39.057257Z","iopub.status.idle":"2023-05-25T10:52:56.431752Z","shell.execute_reply.started":"2023-05-25T10:08:39.057206Z","shell.execute_reply":"2023-05-25T10:52:56.430072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Explanation:\n\n1. It creates a list called `indices` containing the indices of the rows in the fashion data.\n2. It initializes an empty list called `duplicate_ID` to store the duplicate product IDs.\n3. It enters a while loop that continues until the `indices` list is empty.\n4. Inside the loop, it pops the last index from the `indices` list and assigns it to `i`.\n5. It appends the product ID (`fashion_data['asin'].loc[i]`) to the `duplicate_ID` list.\n6. It splits the title of the current row into a list of words and assigns it to `a`.\n7. It enters a nested loop to compare the title of the current row with the remaining rows in the `indices` list.\n8. Inside the nested loop, it splits the title of the current compared row into a list of words and assigns it to `b`.\n9. It calculates the maximum length between the lists `a` and `b`.\n10. It counts the number of matching words between the two lists using `itertools.zip_longest` and assigns it to `count`.\n11. If the difference between the maximum length and the count of matching words is less than 3, it considers the products the same and removes the compared row index from the `indices` list.\n12. After the nested loop, the code continues with the next iteration of the outer loop.\n13. Finally, the code will have populated the `duplicate_ID` list with the product IDs of the similar apparel products based on title comparison, and the `indices` list will contain only the indices of unique items.\n\nIn summary, the code efficiently compares the titles of products using a nested loop and removes the indices of similar products, resulting in the `duplicate_ID` list containing the product IDs of the unique items.","metadata":{}},{"cell_type":"code","source":"#from whole previous products we will consider only the products that are found in previous cell \nfashion_data = fashion_data.loc[fashion_data['asin'].isin(duplicate_ID)]","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:54:16.902621Z","iopub.execute_input":"2023-05-25T10:54:16.903216Z","iopub.status.idle":"2023-05-25T10:54:16.919381Z","shell.execute_reply.started":"2023-05-25T10:54:16.903177Z","shell.execute_reply":"2023-05-25T10:54:16.918292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of data points after removing duplicates: \",fashion_data.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:54:39.500613Z","iopub.execute_input":"2023-05-25T10:54:39.500979Z","iopub.status.idle":"2023-05-25T10:54:39.507353Z","shell.execute_reply.started":"2023-05-25T10:54:39.500950Z","shell.execute_reply":"2023-05-25T10:54:39.505752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fashion_data.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:55:03.515732Z","iopub.execute_input":"2023-05-25T10:55:03.516101Z","iopub.status.idle":"2023-05-25T10:55:03.563678Z","shell.execute_reply.started":"2023-05-25T10:55:03.516071Z","shell.execute_reply":"2023-05-25T10:55:03.561898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's drop null values, if any are present and most null values are present in brand","metadata":{}},{"cell_type":"code","source":"fashion_data = fashion_data.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:02:22.720552Z","iopub.execute_input":"2023-05-25T11:02:22.721131Z","iopub.status.idle":"2023-05-25T11:02:22.759122Z","shell.execute_reply.started":"2023-05-25T11:02:22.721100Z","shell.execute_reply":"2023-05-25T11:02:22.758406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fashion_data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:03:01.722798Z","iopub.execute_input":"2023-05-25T11:03:01.723231Z","iopub.status.idle":"2023-05-25T11:03:01.731245Z","shell.execute_reply.started":"2023-05-25T11:03:01.723195Z","shell.execute_reply":"2023-05-25T11:03:01.729751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have removed duplicate data let's perform some text-preprocessing since \npython can't read text.","metadata":{}},{"cell_type":"code","source":"fashion_data.to_pickle(\"/kaggle/working/16k_dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:03:09.811632Z","iopub.execute_input":"2023-05-25T11:03:09.811996Z","iopub.status.idle":"2023-05-25T11:03:09.860719Z","shell.execute_reply.started":"2023-05-25T11:03:09.811968Z","shell.execute_reply":"2023-05-25T11:03:09.858788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport time\nimport numpy as np\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nimport PIL\nfrom pathlib import Path\nfrom PIL import UnidentifiedImageError\nfrom PIL import Image\nimport requests\nfrom io import BytesIO","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:04:54.414553Z","iopub.execute_input":"2023-05-25T11:04:54.415046Z","iopub.status.idle":"2023-05-25T11:04:56.551820Z","shell.execute_reply.started":"2023-05-25T11:04:54.415006Z","shell.execute_reply":"2023-05-25T11:04:56.550378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There might be many stop words like 'are, is to..' etc and these should not be present while training the model and also special characters should also be removed from the model.**","metadata":{}},{"cell_type":"code","source":"New_fashion_data = pd.read_pickle('/kaggle/working/16k_dataset')","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:05:01.129758Z","iopub.execute_input":"2023-05-25T11:05:01.130134Z","iopub.status.idle":"2023-05-25T11:05:01.154326Z","shell.execute_reply.started":"2023-05-25T11:05:01.130106Z","shell.execute_reply":"2023-05-25T11:05:01.152789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we use the list of stop words that are downloaded from nltk lib\nstop_words = set(stopwords.words('english'))\n\ndef nlp_preprocessing(total_text, index, column):\n    if type(total_text) is not int:\n        string = \"\"\n        for words in total_text.split():\n            #remove the special chars in review like '\"#$@!%^&*()_+-~?>< etc.\n            word = (\"\".join(e for e in words if e.isalnum()))\n            \n            #conver all letters to lower-case\n            word = word.lower()\n            \n            #stop-word removal\n            if not word in stop_words:\n                string += word + \" \"\n        New_fashion_data[column][index] = string","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:05:06.211031Z","iopub.execute_input":"2023-05-25T11:05:06.211465Z","iopub.status.idle":"2023-05-25T11:05:06.227433Z","shell.execute_reply.started":"2023-05-25T11:05:06.211432Z","shell.execute_reply":"2023-05-25T11:05:06.225537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.perf_counter()\n#we take each title and we text-preprocess it\n\nfor index, row in New_fashion_data.iterrows():\n    nlp_preprocessing(row['title'], index, 'title')\n    \n#we print the time it took to preprocess whole titles \nprint(time.perf_counter() - start_time, \"Sec\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:05:21.810903Z","iopub.execute_input":"2023-05-25T11:05:21.811320Z","iopub.status.idle":"2023-05-25T11:05:25.809983Z","shell.execute_reply.started":"2023-05-25T11:05:21.811284Z","shell.execute_reply":"2023-05-25T11:05:25.808010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"New_fashion_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:05:35.394052Z","iopub.execute_input":"2023-05-25T11:05:35.394480Z","iopub.status.idle":"2023-05-25T11:05:35.409414Z","shell.execute_reply.started":"2023-05-25T11:05:35.394450Z","shell.execute_reply":"2023-05-25T11:05:35.407740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"New_fashion_data.to_pickle(\"/kaggle/working/16k_dataset_no_stop_words\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:06:24.418047Z","iopub.execute_input":"2023-05-25T11:06:24.418447Z","iopub.status.idle":"2023-05-25T11:06:24.455835Z","shell.execute_reply.started":"2023-05-25T11:06:24.418418Z","shell.execute_reply":"2023-05-25T11:06:24.454953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# let's write some utility functions","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import gridspec\nfrom collections import Counter\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\ndef display_img(url, ax, fig):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    plt.imshow(img)\n\ndef plot_heatmap(keys, values, labels, url, text):\n    gs = gridspec.GridSpec(2, 2, width_ratios=[4, 1], height_ratios=[4, 1]) \n    fig = plt.figure(figsize=(25, 3))\n    \n    ax = plt.subplot(gs[0])\n    ax = sns.heatmap(np.array([values]), annot=np.array([labels]))\n    ax.set_xticklabels(keys)\n    ax.set_title(text)\n    \n    ax = plt.subplot(gs[1])\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    \n    display_img(url, ax, fig)\n    \n    plt.show()\n\ndef plot_heatmap_image(doc_id, vec1, vec2, url, text, model):\n    intersection = set(vec1.keys()) & set(vec2.keys())\n    \n    for i in vec2:\n        if i not in intersection:\n            vec2[i] = 0\n    \n    keys = list(vec2.keys())\n    values = [vec2[x] for x in vec2.keys()]\n    \n    if model == 'bag_of_words':\n        labels = values\n    elif model == 'tfidf':\n        labels = []\n        for x in vec2.keys():\n            if x in tfidf_title_vectorizer.vocabulary_:\n                labels.append(tfidf_title_features[doc_id, tfidf_title_vectorizer.vocabulary_[x]])\n            else:\n                labels.append(0)\n    elif model == 'idf':\n        labels = []\n        for x in vec2.keys():\n            if x in idf_title_vectorizer.vocabulary_:\n                labels.append(idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[x]])\n            else:\n                labels.append(0)\n    \n    plot_heatmap(keys, values, labels, url, text)\n\ndef text_to_vector(text):\n    word = re.compile(r'\\w+')\n    words = word.findall(text)\n    return Counter(words)\n\ndef get_result(doc_id, content_a, content_b, url, model):\n    text1 = content_a\n    text2 = content_b\n    vector1 = text_to_vector(text1)\n    vector2 = text_to_vector(text2)\n    plot_heatmap_image(doc_id, vector1, vector2, url, text2, model)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:07:36.730999Z","iopub.execute_input":"2023-05-25T11:07:36.731647Z","iopub.status.idle":"2023-05-25T11:07:37.091803Z","shell.execute_reply.started":"2023-05-25T11:07:36.731611Z","shell.execute_reply":"2023-05-25T11:07:37.091027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Explanation:\n\n1. The `display_img` function takes a URL as input, downloads the image from the URL, and displays it.\n2. The `plot_heatmap` function takes lists of keys, values, and labels, along with an image URL and text as inputs. It plots a heatmap with the given data and displays the image.\n3. The `plot_heatmap_image` function takes the document ID, two vector dictionaries, an image URL, text, and a model type as inputs. It finds the intersection of keys in both vectors, sets the values of non-intersecting keys to zero, and then calls the `plot_heatmap` function to plot the heatmap and display the image.\n4. The `text_to_vector` function takes a text string as input, splits it into words, and counts the occurrences of each word. It returns a dictionary with words as keys and their respective counts as\n\n values.\n5. The `get_result` function takes the document ID, two content strings, an image URL, and a model type as inputs. It converts the content strings into vector dictionaries using the `text_to_vector` function and then calls the `plot_heatmap_image` function to plot the heatmap and display the image.\n\nOverall, these utility functions are used to visualize the comparison between two text documents by plotting a heatmap of common words and displaying an associated image. It provides a visual representation of the similarity between the documents based on the words they share.","metadata":{}},{"cell_type":"markdown","source":"1. Bag of Words (BoW) Based Product Similarity","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ntitle_vectorizer = CountVectorizer()\ntitle_features = title_vectorizer.fit_transform(New_fashion_data['title'])\n\nfrom sklearn.metrics import pairwise_distances\n\ndef bag_of_words_model(doc_id, num_results):\n    pairwise_dist = pairwise_distances(title_features, title_features[doc_id])\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists = np.sort(pairwise_dist.flatten())[0:num_results]\n    df_indices = list(New_fashion_data.index[indices])\n    \n    for i in range(len(indices)):\n        get_result(indices[i], New_fashion_data['title'].loc[df_indices[0]], New_fashion_data['title'].loc[df_indices[i]], New_fashion_data['medium_image_url'].loc[df_indices[i]], 'bag_of_words')\n        print('ASIN:', New_fashion_data['asin'].loc[df_indices[i]])\n        print('Brand:', New_fashion_data['brand'].loc[df_indices[i]])\n        print('Title:', New_fashion_data['title'].loc[df_indices[i]])\n        print('Euclidean Similarity With The Query Image:', pdists[i])\n        print('-.'*60)\n\nbag_of_words_model(921, 20)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:07:43.160589Z","iopub.execute_input":"2023-05-25T11:07:43.160949Z","iopub.status.idle":"2023-05-25T11:07:43.385866Z","shell.execute_reply.started":"2023-05-25T11:07:43.160919Z","shell.execute_reply":"2023-05-25T11:07:43.384609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Explanation:\n\n1. The code uses the `CountVectorizer` from scikit-learn to convert the titles of fashion data into a feature matrix (`title_features`), where each row represents a document and each column represents a word in the corpus. The shape of `title_features` is the number of data points (rows) by the number of words in the corpus (columns).\n2. The `pairwise_distances` function from scikit-learn calculates the pairwise cosine distances between the feature vectors of the titles. It measures the similarity between the input apparel and all other apparels in the data.\n3. The indices of the smallest distances (`num_results`) are sorted and stored in `indices`, and the corresponding distances are stored in `pdists`.\n\n        np.argsort will return indices of 9 smallest distances\n        pdists will store the 9 smallest distances\n        \n        \n4. The loop iterates over the indices and calls the `get_result` function to plot a heatmap and display an associated image for each similar apparel. It also prints the ASIN, brand, title, and Euclidean similarity with the query image.\n5. Finally, the `bag_of_words_model` function is called with a specific document ID (921) and the number of similar results desired (20).\n6. In the output heat map each value represents the count value of the label word, the color represents the intersection with inputs title\n\nchange the index and number of results and check for yourself.\n\nOverall, this code performs a bag-of-words model using the cosine similarity metric to find similar products based on their titles. It visualizes the results by plotting heatmaps and displaying images of the similar apparels.","metadata":{}},{"cell_type":"markdown","source":"2. TF IDF Based Product Similarity","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_title_vectorizer = TfidfVectorizer(min_df=0)\ntfidf_title_features = tfidf_title_vectorizer.fit_transform(New_fashion_data['title'])\n\nfrom sklearn.metrics import pairwise_distances\n\ndef tfidf_model(doc_id, num_results):\n    pairwise_dist = pairwise_distances(tfidf_title_features, tfidf_title_features[doc_id])\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists = np.sort(pairwise_dist.flatten())[0:num_results]\n    df_indices = list(New_fashion_data.index[indices])\n\n    for i in range(len(indices)):\n        get_result(indices[i], New_fashion_data['title'].loc[df_indices[0]], New_fashion_data['title'].loc[df_indices[i]], New_fashion_data['medium_image_url'].loc[df_indices[i]], 'tfidf')\n        print('ASIN:', New_fashion_data['asin'].loc[df_indices[i]])\n        print('Brand:', New_fashion_data['brand'].loc[df_indices[i]])\n        print('Title:', New_fashion_data['title'].loc[df_indices[i]])\n        print('Euclidean Similarity With The Query Image:', pdists[i])\n        print('-.'*60)\n\ntfidf_model(921, 20)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:21:55.909385Z","iopub.execute_input":"2023-05-25T11:21:55.911462Z","iopub.status.idle":"2023-05-25T11:21:56.102272Z","shell.execute_reply.started":"2023-05-25T11:21:55.911402Z","shell.execute_reply":"2023-05-25T11:21:56.100945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Explanation:\n\n1. The code uses the `TfidfVectorizer` from scikit-learn to convert the titles of fashion data into a feature matrix (`tfidf_title_features`), where each row represents a document and each column represents a word in the corpus. The shape of `tfidf_title_features` is the number of data points (rows) by the number of words in the corpus (columns).\n2. The `pairwise_distances` function from scikit-learn calculates the pairwise cosine distances between the TF-IDF feature vectors of the titles. It measures the similarity between the input apparel and all other apparels in the data.\n3. The indices of the smallest distances (`num_results`) are sorted and stored in `indices`, and the corresponding distances are stored in `pdists`.\n4. The loop iterates over the indices and calls the `get_result` function to plot a heatmap and display an associated image for each similar apparel. It also prints the ASIN, brand, title, and Euclidean similarity with the query image.\n5. Finally, the `tfidf_model` function is called with a specific document ID (921) and the number of similar results desired (20).\n\nOverall, this code performs a TF-IDF model using the cosine similarity metric to find similar products based on their titles. It visualizes the results by plotting heatmaps and displaying images of the similar apparels.","metadata":{}},{"cell_type":"markdown","source":"3. IDF Based Product Similarity i.e., let's drop TF and see","metadata":{}},{"cell_type":"code","source":"\nidf_title_vectorizer = CountVectorizer()\nidf_title_features = idf_title_vectorizer.fit_transform(New_fashion_data['title'])\nidf_title_features.get_shape()\n\ndef n_containing(word):\n    return sum(1 for blob in New_fashion_data['title'] if word in blob.split())\n\ndef idf(word):\n    return math.log(New_fashion_data.shape[0] / (n_containing(word)))\n\nidf_title_features = idf_title_features.astype(np.float)\n\nfor i in idf_title_vectorizer.vocabulary_.keys():\n    idf_val = idf(i)\n    for j in idf_title_features[:, idf_title_vectorizer.vocabulary_[i]].nonzero()[0]:\n        idf_title_features[j, idf_title_vectorizer.vocabulary_[i]] = idf_val\n\ndef idf_model(doc_id, num_results):\n    pairwise_dist = pairwise_distances(idf_title_features, idf_title_features[doc_id])\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists = np.sort(pairwise_dist.flatten())[0:num_results]\n    df_indices = list(New_fashion_data.index[indices])\n\n    for i in range(len(indices)):\n        get_result(indices[i], New_fashion_data['title'].loc[df_indices[0]], New_fashion_data['title'].loc[df_indices[i]], New_fashion_data['medium_image_url'].loc[df_indices[i]], 'idf')\n        print('ASIN:', New_fashion_data['asin'].loc[df_indices[i]])\n        print('Brand:', New_fashion_data['brand'].loc[df_indices[i]])\n        print('Title:', New_fashion_data['title'].loc[df_indices[i]])\n        print('Euclidean Distance From The Query Image:', pdists[i])\n        print('-.'*60)\n\nidf_model(921, 20)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:23:42.552843Z","iopub.execute_input":"2023-05-25T11:23:42.553757Z","iopub.status.idle":"2023-05-25T11:23:42.765261Z","shell.execute_reply.started":"2023-05-25T11:23:42.553723Z","shell.execute_reply":"2023-05-25T11:23:42.764619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Explanation:\n\n1. The code uses the `CountVectorizer` from scikit-learn to convert the titles of fashion data into a feature matrix (`idf_title_features`), where each row represents a document and each column represents a word in the corpus. The shape of `idf_title_features` is the number of data points (rows) by the number of words in the corpus (columns).\n2. The `n_containing` function calculates the number of documents in the corpus that contain a specific word.\n3. The `idf` function calculates the inverse document frequency (IDF) for a given word. It is computed as the logarithm of the total number of documents divided by the number of documents that contain the word.\n4. The feature matrix `idf_title_features` is converted to float type.\n5. The loop iterates over the vocabulary of the `idf_title_vectorizer`, calculates the IDF value for each word, and replaces the corresponding count values in the feature matrix with the IDF values.\n6. The `idf_model` function is defined to find similar apparel based on the IDF-weighted title features. It calculates the pairwise distances between the IDF-weighted feature vectors of the titles using cosine similarity.\n7. The indices of the smallest distances (`num_results`) are sorted and stored in `indices`, and the corresponding distances are stored in `pdists`.\n8. The loop iterates over the indices and calls the `get_result` function to plot a heatmap and display an associated image for each similar apparel. It also prints the ASIN, brand, title, and Euclidean distance from the query image.\n9. Finally, the `idf_model` function is called with a specific document ID (921\n\n) and the number of similar results desired (20).\n\nOverall, this code performs an IDF model using cosine similarity to find similar products based on their titles. It applies IDF weighting to the count-based title features, calculates the pairwise distances, and visualizes the results using heatmaps and images.\n\n\n# let's use word2vec\n\nwhat is word2vec?\nWord2Vec is a widely used technique in natural language processing (NLP) that aims to represent words as dense vector embeddings in a continuous vector space. It was introduced by Tomas Mikolov et al. in 2013 and has since become a popular method for learning word representations.\n\nThe main idea behind Word2Vec is to learn word embeddings by training a neural network on large amounts of text data. There are two primary architectures used in Word2Vec: Continuous Bag of Words (CBOW) and Skip-gram.\n\n1. Continuous Bag of Words (CBOW): In this architecture, the model predicts the current word based on the context of surrounding words. The input to the model is a set of context words, and the output is the target word. CBOW is useful when we want to predict missing words or estimate the probability of a word given its context.\n\n2. Skip-gram: This architecture is the inverse of CBOW. It predicts the surrounding context words given a target word. The input to the model is a target word, and the output is a set of context words. Skip-gram is useful when we want to find words that are semantically related or to perform tasks such as word analogy.\n\nBoth CBOW and Skip-gram models are trained by feeding pairs of target and context words into a neural network. The network is trained to maximize the likelihood of predicting the correct context words given the target word. During training, the model adjusts the word vectors in such a way that similar words have similar vector representations in the embedding space.\n\nThe resulting word embeddings capture semantic and syntactic relationships between words. Words with similar meanings or that often appear in similar contexts will have similar vector representations. These word embeddings can be used in various NLP tasks such as sentiment analysis, machine translation, information retrieval, and more.\n\nWord2Vec has been influential in the field of NLP because it provides a computationally efficient and effective way to learn high-dimensional word representations from large text corpora, enabling machines to better understand and process natural language.","metadata":{}},{"cell_type":"code","source":"from gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nimport pickle\n\nmodel = KeyedVectors.load_word2vec_format('/kaggle/input/word-2-vec/GoogleNews-vectors-negative300.bin', binary=True)\n\n#or use \n\n#model = KeyedVectors.load_word2vec_format('/kaggle/input/amazon-apparel-dataset/word2vec_model', binary=True)\n# both are same it's just size difference","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:54:49.705566Z","iopub.execute_input":"2023-05-25T11:54:49.706364Z","iopub.status.idle":"2023-05-25T11:55:16.997071Z","shell.execute_reply.started":"2023-05-25T11:54:49.706318Z","shell.execute_reply":"2023-05-25T11:55:16.995954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"new utility functions","metadata":{}},{"cell_type":"code","source":"# another utility function\n\ndef get_word_vec(sentence, doc_id, m_name):\n    vec = []\n    for i in sentence.split():\n        if i in vocab:\n            if m_name == 'weighted' and i in idf_title_vectorizer.vocabulary_:\n                vec.append(idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[i]] * model[i])\n            elif m_name == 'avg':\n                vec.append(model[i])\n        else:\n            vec.append(np.zeros(shape=(300,)))\n    return np.array(vec)\n\ndef get_distance(vec1, vec2):\n    final_dist = []\n    for i in vec1:\n        dist = []\n        for j in vec2:\n            dist.append(np.linalg.norm(i-j))\n        final_dist.append(np.array(dist))\n    return np.array(final_dist)\n\ndef heat_map_w2v(sentence1, sentence2, url, doc_id1, doc_id2, model):\n    s1_vec = get_word_vec(sentence1, doc_id1, model)\n    s2_vec = get_word_vec(sentence2, doc_id2, model)\n    s1_s2_dist = get_distance(s1_vec, s2_vec)\n    \n    gs = gridspec.GridSpec(2, 2, width_ratios=[4,1], height_ratios=[2,1]) \n    fig = plt.figure(figsize=(15,15))\n    \n    ax = plt.subplot(gs[0])\n    ax = sns.heatmap(np.round(s1_s2_dist,4), annot=True)\n    ax.set_title(sentence2)\n    \n    ax = plt.subplot(gs[1])\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    display_img(url, ax, fig)\n    \n    plt.show()\n\nvocab = model.key_to_index.keys() # if you are using google's word2vec\n\n#vocab = model.keys() #if you are using the 56 MB one\n\ndef build_avg_vec(sentence, num_features, doc_id, m_name):\n    featureVec = np.zeros((num_features), dtype=\"float32\")\n    nwords = 0\n    \n    for word in sentence.split():\n        nwords += 1\n        if word in vocab:\n            if m_name == 'weighted' and word in idf_title_vectorizer.vocabulary_:\n                featureVec = np.add(featureVec, idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[word]] * model[word])\n            elif m_name == 'avg':\n                featureVec = np.add(featureVec, model[word])\n    if(nwords > 0):\n        featureVec = np.divide(featureVec, nwords)\n    return featureVec\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T12:23:46.273217Z","iopub.execute_input":"2023-05-25T12:23:46.273652Z","iopub.status.idle":"2023-05-25T12:23:46.289048Z","shell.execute_reply.started":"2023-05-25T12:23:46.273619Z","shell.execute_reply":"2023-05-25T12:23:46.287571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The utility functions in the above code serves the following purposes:\n\n1. `get_word_vec`: Given a sentence, document ID, and model name ('avg' or 'weighted'), it returns a numpy array of word vectors. Each row of the array represents the word vector (weighted or average) of a word in the sentence.\n\n2. `get_distance`: Given two arrays of word vectors (`vec1` and `vec2`), it calculates the pairwise Euclidean distance between the vectors and returns the distance matrix.\n\n3. `heat_map_w2v`: This function visualizes the distance matrix as a heatmap using Seaborn. It also displays an image related to the recommended apparel.\n\n4. `build_avg_vec`: Given a sentence, number of features, document ID, and model name, it builds and returns the average word vector of the sentence.\n\nThese utility functions are used in the code to calculate and visualize the word vector representations and distances between product titles, allowing for recommendation and comparison based on semantic similarity.","metadata":{}},{"cell_type":"markdown","source":"1. Average Word2Vec Based Product Similarity","metadata":{}},{"cell_type":"code","source":"doc_id = 0\nw2v_title = []\nfor i in New_fashion_data['title']:\n    w2v_title.append(build_avg_vec(i, 300, doc_id, 'avg'))\n    doc_id += 1\nw2v_title = np.array(w2v_title)\n\ndef avg_w2v_model(doc_id, num_results):\n    pairwise_dist = pairwise_distances(w2v_title, w2v_title[doc_id].reshape(1,-1))\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists = np.sort(pairwise_dist.flatten())[0:num_results]\n    df_indices = list(New_fashion_data.index[indices])\n    \n    for i in range(0, len(indices)):\n        heat_map_w2v(New_fashion_data['title'].loc[df_indices[0]], New_fashion_data['title'].loc[df_indices[i]], New_fashion_data['medium_image_url'].loc[df_indices[i]], indices[0], indices[i], 'avg')\n        print('ASIN:', New_fashion_data['asin'].loc[df_indices[i]])\n        print('Brand:', New_fashion_data['brand'].loc[df_indices[i]])\n        print('Title:', New_fashion_data['title'].loc[df_indices[i]])\n        print('Euclidean Distance From The Query Image:', pdists[i])\n        print('-.'*60)\n\navg_w2v_model(921, 20)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T12:01:56.735286Z","iopub.execute_input":"2023-05-25T12:01:56.736510Z","iopub.status.idle":"2023-05-25T12:01:57.336026Z","shell.execute_reply.started":"2023-05-25T12:01:56.736461Z","shell.execute_reply":"2023-05-25T12:01:57.334471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code performs the following tasks:\n\n1. It creates an array `w2v_title` to store the average word vector representations of each title in the fashion dataset.\n\n2. The function `avg_w2v_model` takes a document ID and the desired number of results as input. It calculates the pairwise distances between the word vectors of the given document and all other documents using the `pairwise_distances` function. It then retrieves the indices and distances of the `num_results` smallest distances.\n\n3. For each result, it displays a heatmap comparing the title of the given document with the title of the recommended document. It also prints additional information such as ASIN, brand, title, and the Euclidean distance from the query image.\n\nOverall, this code utilizes average word vector representations and pairwise distances to find similar fashion items based on their titles. It visualizes the similarities and provides additional details for the recommended items.","metadata":{}},{"cell_type":"markdown","source":"2. IDF Weighted Word2Vec Based Product Similarity","metadata":{}},{"cell_type":"code","source":"doc_id = 0\nw2v_title_weight = []\nfor i in New_fashion_data['title']:\n    w2v_title_weight.append(build_avg_vec(i, 300, doc_id, 'weighted'))\n    doc_id += 1\nw2v_title_weight = np.array(w2v_title_weight)\n\n\ndef weighted_w2v_model(doc_id, num_results):\n    pairwise_dist = pairwise_distances(w2v_title_weight, w2v_title_weight[doc_id].reshape(1, -1))\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists = np.sort(pairwise_dist.flatten())[0:num_results]\n    df_indices = list(New_fashion_data.index[indices])\n\n    split_titles = [New_fashion_data['title'].loc[df_indices[i]].split() for i in range(len(indices))]\n    max_words = max(len(title) for title in split_titles)\n    padded_titles = [title + [''] * (max_words - len(title)) for title in split_titles]\n\n    title1 = ' '.join(padded_titles[0])\n\n    for i in range(len(indices)):\n        title2 = ' '.join(padded_titles[i])\n        heat_map_w2v(title1, title2, New_fashion_data['medium_image_url'].loc[df_indices[i]], indices[0], indices[i], 'weighted')\n        print('ASIN:', New_fashion_data['asin'].loc[df_indices[i]])\n        print('Brand:', New_fashion_data['brand'].loc[df_indices[i]])\n        print('Title:', New_fashion_data['title'].loc[df_indices[i]])\n        print('Euclidean Distance From The Query Image:', pdists[i])\n        print('-.' * 60)\n\n\nweighted_w2v_model(921, 20)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T12:02:38.208123Z","iopub.execute_input":"2023-05-25T12:02:38.208688Z","iopub.status.idle":"2023-05-25T12:02:41.952794Z","shell.execute_reply.started":"2023-05-25T12:02:38.208652Z","shell.execute_reply":"2023-05-25T12:02:41.951029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code performs the following tasks:\n\n1. It creates an array `w2v_title_weight` to store the weighted word vector representations of each title in the fashion dataset.\n\n2. The function `weighted_w2v_model` takes a document ID and the desired number of results as input. It calculates the pairwise distances between the weighted word vectors of the given document and all other documents using the `pairwise_distances` function. It then retrieves the indices and distances of the `num_results` smallest distances.\n\n3. It prepares the titles of the recommended items for visualization by splitting them into individual words and padding them with empty strings to match the maximum number of words among all titles.\n\n4. For each result, it displays a heatmap comparing the title of the given document with the title of the recommended document. It also prints additional information such as ASIN, brand, title, and the Euclidean distance from the query image.\n\nOverall, this code uses weighted word vector representations and pairwise distances to find similar fashion items based on their titles. It visualizes the similarities and provides additional details for the recommended items.","metadata":{}},{"cell_type":"markdown","source":"Weighted Similarity Using Brand & Color","metadata":{}},{"cell_type":"code","source":"from scipy.sparse import hstack\nNew_fashion_data['brand'].fillna(value=\"Not Given\", inplace=True)\nbrands = [x.replace(\" \", \"-\") for x in New_fashion_data['brand'].values]\ntypes = [x.replace(\" \", \"-\") for x in New_fashion_data['product_type_name'].values]\ncolors = [x.replace(\" \", \"-\") for x in New_fashion_data['color'].values]\n\nbrand_vectorizer = CountVectorizer()\nbrand_features = brand_vectorizer.fit_transform(brands)\n\ntype_vectorizer = CountVectorizer()\ntype_features = type_vectorizer.fit_transform(types)\n\ncolor_vectorizer = CountVectorizer()\ncolor_features = color_vectorizer.fit_transform(colors)\n\nextra_features = hstack((brand_features, type_features, color_features)).tocsr()\n\nimport plotly\nimport plotly.figure_factory as ff\n\ndef heat_map_w2v_brand(sentance1, sentance2, url, doc_id1, doc_id2, df_id1, df_id2, model):\n    s1_vec = get_word_vec(sentance1, doc_id1, model)\n    s2_vec = get_word_vec(sentance2, doc_id2, model)\n    s1_s2_dist = get_distance(s1_vec, s2_vec)\n\n    data_matrix = [['Asin', 'Brand', 'Color', 'Product type'],\n                   [New_fashion_data['asin'].loc[df_id1], brands[doc_id1], colors[doc_id1], types[doc_id1]],\n                   [New_fashion_data['asin'].loc[df_id2], brands[doc_id2], colors[doc_id2], types[doc_id2]]]\n\n    colorscale = [[0, '#1d004d'], [.5, '#f2e5ff'], [1, '#f2e5d1']]\n\n    table = ff.create_table(data_matrix, index=True, colorscale=colorscale)\n    plotly.offline.iplot(table, filename='simple_table')\n\n    gs = gridspec.GridSpec(25, 15)\n    fig = plt.figure(figsize=(25, 5))\n    ax1 = plt.subplot(gs[:, :-5])\n    ax1 = sns.heatmap(np.round(s1_s2_dist, 6), annot=True)\n    ax1.set_xticks(np.arange(len(sentance2.split())))\n    ax1.set_xticklabels(sentance2.split())\n    ax1.set_yticks(np.arange(len(sentance1.split())))\n    ax1.set_yticklabels(sentance1.split())\n    ax1.set_title(sentance2)\n\n    ax2 = plt.subplot(gs[:, 10:16])\n    ax2.grid(False)\n    ax2.set_xticks([])\n    ax2.set_yticks([])\n\n    display_img(url, ax2, fig)\n\n    plt.show()\n\n\ndef idf_w2v_brand(doc_id, w1, w2, num_results):\n    idf_w2v_dist = pairwise_distances(w2v_title_weight, w2v_title_weight[doc_id].reshape(1, -1))\n    ex_feat_dist = pairwise_distances(extra_features, extra_features[doc_id].reshape(1, -1))\n    pairwise_dist = (w1 * idf_w2v_dist + w2 * ex_feat_dist) / float(w1 + w2)\n\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists = np.sort(pairwise_dist.flatten())[0:num_results]\n    df_indices = list(New_fashion_data.index[indices])\n\n    title1 = New_fashion_data['title'].loc[df_indices[0]]\n\n    for i in range(len(indices)):\n        title2 = New_fashion_data['title'].loc[df_indices[i]]\n        heat_map_w2v_brand(title1, title2, New_fashion_data['medium_image_url'].loc[df_indices[i]], indices[0], indices[i], df_indices[0], df_indices[i], 'weighted')\n        print('ASIN:', New_fashion_data['asin'].loc[df_indices[i]])\n        print('Brand:', New_fashion_data['brand'].loc[df_indices[i]])\n        print('Title:', New_fashion_data['title'].loc[df_indices[i]])\n        print('Euclidean Distance From The Query Image:', pdists[i])\n        print('-.' * 60)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T12:25:47.363423Z","iopub.execute_input":"2023-05-25T12:25:47.363827Z","iopub.status.idle":"2023-05-25T12:25:47.609172Z","shell.execute_reply.started":"2023-05-25T12:25:47.363795Z","shell.execute_reply":"2023-05-25T12:25:47.607113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code performs the following tasks:\n\n1. It preprocesses the 'brand', 'product_type_name', and 'color' columns of the fashion dataset. It replaces any null values in the 'brand' column with the string \"Not Given\" and replaces spaces in each column with hyphens.\n\n2. It uses `CountVectorizer` to create count-based features for the preprocessed brand, product type, and color values.\n\n3. It combines the count-based features into a single sparse matrix using `hstack`.\n\n4. The function `heat_map_w2v_brand` takes two input titles, image URL, document IDs, and other parameters. It calculates the word vectors and pairwise distances between the two titles and visualizes them using heatmaps and an image display.\n\n5. The function `idf_w2v_brand` calculates the pairwise distances between the word vectors of the given document and all other documents using a weighted combination of word vector distances (`idf_w2v_dist`) and extra features distances (`ex_feat_dist`). It retrieves the indices and distances of the `num_results` smallest distances and visualizes them using the `heat_map_w2v_brand` function.\n\nOverall, this code adds additional features to the fashion dataset based on brand, product type, and color. It then uses these features and word vectors to calculate pairwise distances and visualize similarities between fashion items.","metadata":{}},{"cell_type":"code","source":"#w1 - title vector weight = 5\n#w2 - brand and color weight = 5\n\nidf_w2v_brand(921, 5, 5, 20)\n#in the give heat map, each cell contains the euclidean distance between words i, j","metadata":{"execution":{"iopub.status.busy":"2023-05-25T12:49:29.028736Z","iopub.execute_input":"2023-05-25T12:49:29.029635Z","iopub.status.idle":"2023-05-25T12:49:41.611594Z","shell.execute_reply.started":"2023-05-25T12:49:29.029603Z","shell.execute_reply":"2023-05-25T12:49:41.609928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#w1 - title vector weight = 5\n#w2 - brand and color weight = 50\n\nidf_w2v_brand(921, 5, 50, 20)\n#in the give heat map, each cell contains the euclidean distance between words i, j","metadata":{"execution":{"iopub.status.busy":"2023-05-25T12:50:19.272025Z","iopub.execute_input":"2023-05-25T12:50:19.272503Z","iopub.status.idle":"2023-05-25T12:50:32.142555Z","shell.execute_reply.started":"2023-05-25T12:50:19.272465Z","shell.execute_reply":"2023-05-25T12:50:32.140816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OK! all text related is done.\nlet's proceed with images.It's better to do the below things in local system since it will take a lot of time for both downloading and training the images in CNN","metadata":{}},{"cell_type":"code","source":"New_fashion_data = pd.read_pickle(\"/kaggle/working/16k_dataset_no_stop_words\")\n\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\nfor index, row in New_fashion_data.iterrows():\n        url = row['medium_image_url']\n        response = requests.get(url)\n        img = Image.open(BytesIO(response.content))\n        img.save('../Images/'+row['asin']+'.jpeg') # store it in a file called Images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras import applications\nfrom sklearn.metrics import pairwise_distances\nimport matplotlib.pyplot as plt\nimport requests\nfrom PIL import Image\nimport pandas as pd\nimport pickle\nfrom IPython.display import display, Image, SVG","metadata":{"execution":{"iopub.status.busy":"2023-05-30T08:46:38.886704Z","iopub.execute_input":"2023-05-30T08:46:38.887093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dimensions of our images.\nimg_width, img_height = 224, 224\n\ntop_model_weights_path = 'bottleneck_fc_model.h5'\ntrain_data_dir = 'Images/'\nnb_train_samples = #the number that you get after saving the previous file\nepochs = 50\nbatch_size = 1\n\n\ndef save_bottlebeck_features():\n    #function to compute VGG-16 CNN for image feature extraction.\n    \n    asins = []\n    datagen = ImageDataGenerator(rescale=1. / 255)\n    \n    #build the VGG16 network\n    model = applications.VGG16(include_top=False, weights='imagenet')\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\n\n    for i in generator.filenames:\n        asins.append(i[2:-5])\n\n    bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n    bottleneck_features_train = bottleneck_features_train.reshape((16042,25088))\n    \n    # be sure togive proper path of the directory where you want the below files to be saved\n    \n    np.save(open('../16k_Products_Data_CNN.npy', 'wb'), bottleneck_features_train)\n    np.save(open('../16k_Products_Data_CNN_asins.npy', 'wb'), np.array(asins))\n    \n\nsave_bottlebeck_features()\n\n#load the features and corresponding ASINS info\nbottleneck_features_train = np.load('16k_Products_Data_CNN.npy')\n\nasins = np.load('16k_Products_Data_CNN_asins.npy')\nasins = list(asins)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's see product similarity on visual features","metadata":{}},{"cell_type":"code","source":"df_asins = list(apparel_data['asin'])\n\n#get similar products using CNN features (VGG-16)\ndef get_similar_products_cnn(doc_id, num_results):\n    doc_id = asins.index(df_asins[doc_id])\n    pairwise_dist = pairwise_distances(bottleneck_features_train, bottleneck_features_train[doc_id].reshape(1,-1))\n\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n\n    for i in range(len(indices)):\n        rows = apparel_data[['medium_image_url','title']].loc[apparel_data['asin']==asins[indices[i]]]\n        for indx, row in rows.iterrows():\n            display(Image(url=row['medium_image_url'], embed=True))\n            print('Product Title: ', row['title'])\n            print('Euclidean Distance From The Query Image:', pdists[i])\n            print('Amazon URL: www.amzon.com/dp/'+ asins[indices[i]])\n            \n            \nget_similar_products_cnn(921, 20)","metadata":{},"execution_count":null,"outputs":[]}]}